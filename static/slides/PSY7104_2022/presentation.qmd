---
title: "Adresser la crise de réplicabilité : La science ouverte et au-delà"
subtitle: "PSY7104 : Méthodes d’observation directe et indirecte "
author: Rémi Thériault
date: "`r Sys.time()`"
format:
    revealjs: 
        theme: solarized
        slide-number: true
        embed-resources: true
        standalone: true
editor: source
css: styles.css
---

## Crise de réplicabilité {.center}

::: {.notes}

Dans cette présentation, je vais tenter de vous convaincre que le mouvement de la science ouverte est insuffisant pour adresser les problèmes systémiques auxquelles la science, et la psychologie notamment, font face, et je couvrerai quelques unes des initiatives d'après moi les plus intéressantes et prometteuses, ainsi que d'autres suggestions pour le futur.

:::

---

![](images/winning.png){fig-align="center"}

---

![](images/future_og.jpg){fig-align="center"}

---

![](images/hierarchy.png){fig-align="center"}

::: {.notes}

Souvent les méta-analyses sont simplement pas bonnes. On pourrait même dire que des fois c'est de la merde en fait. Mais comment je sais que c'est de la merde? Et bien, je me base sur mon jugement personnel. Mais comment je sais que mon jugement personnel est valide? Certains chercheurs très intelligents que je suis sur Twitter sont d'accord avec moi. Mais comment je sais que ces chercheurs sur Twitter sont très intelligents? Eh bien je peux penser à plein d'exemples où ils ont eu raison. Et comment je sais que ces exemples là comptent pour quelque chose? Et bien ils ont souvent publié sur précisément ce sujet par le passé. Et comment on sait que leurs publications sont bonnes? Eh bien, il y a eu plusieurs méta-analyses sur la question. Et comment je sais que ces méta-analyses sont bonnes ou pas? Et bien, je me base sur mon jugement... Et comment je sais que mon jugement...?

:::

---

![](images/se_ouroboros.png){fig-align="center"}

::: {.small}
(Source: https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/)
:::

::: {.notes}
Ouroboros, garbage in, garbage out...

:::

---

![](images/email.png){fig-align="center"}

![](images/Bem1.png){.absolute top=100 right=200 width="250" height="250"}

---

![](images/wheelofscience.png){fig-align="center"}

::: {.notes}

Mauvaises pratiques en recherche

1. Plusieurs (trop de) variables dépendantes
2. Ne pas rapporter toutes les conditions
3. Arrondir de manière généreuse
4. P-Hacking et HARKing (« Hypothesizing After Results are
Known »)
5. Exclusion arbitraire de certaines données
6. Arrêter la collecte de données plus tôt que prévu (quand on a
un effet)/snooping
7. Rapporter seulement les expériences significatives et déclarer
les autres comme « pilotes » (effet tiroir)

:::

## Question 1 {.center}

Manque d'intégrité en recherche dans nos milieux?

« Dénoncer » les mauvaises pratiques ou pas?

::: {.notes}

- pas illégal, zone grise
- data peeking, Brian Wansin (p-hacking, pas fraude)
- à quel point on est prêt à brasser le système
- résistance à partager les données

:::

## La science ouverte {.center}

![](images/open2.png){fig-align="center"}

::: {.small}
(Source: https://i0.wp.com/vusci.blog/wp-content/uploads/2020/04/rtea-3-2-e1587204530638.jpg)
:::

---

![](images/open.jpg){fig-align="center"}

::: {.small}
(Source: https://citizenscience.org.au/wp-content/uploads/2020/05/Open-Science.jpg)
:::

## Mise des données, matériels, code en ligne

>The obvious antidote [to the lack of replication] is openly shared data, materials, and code used to analyze the data. Some journals have begun to require this type of sharing as a condition of publication. More commonly, journals have offered a simple acknowledgment of open data, materials, and code using the badge system described earlier.[^1]

[^1]: Wiggins & Christopherson (2019)

::: {.notes}
> One barrier to replication is opacity in methods and analysis. When researchers approach a scientific investigation as if their methods were a secret recipe, then it naturally follows that other labs would be unable to recreate their analyses and test their exact methods. At a minimum, researchers are required to share data with other professionals who wish to verify their analysis (APA, 2002). However, even with this data-sharing provision included in the APA ethical code, compliance is far from universal.

:::

---

![](images/hierarchy2.png){fig-align="center"}

::: {.small}
(Source: https://osf.io/2jt9u/)
:::

---

> Nosek and Lakens (2014) likewise proposed a major change to peer review in their call for journals to adopt registered reports.[^1]

![](images/reports.png){fig-align="center"}

[^1]: Wiggins & Christopherson (2019)

---

![](images/nosek.png){fig-align="center"}

---

![](images/lakens.png){fig-align="center"}

---

![](images/magic.png){fig-align="center"}

---

![](images/effectsize.png){fig-align="center"}

## « Tag » confirmatoire vs. exploratoire

Études non-préenregistrées : confirmatoire ou exploratoire? Ambigu! Et préenregistrement optionnel!

> This, they argue, would remove the possibility of misrepresenting their research through omission and put them in a position to have to actively deceive in order to misrepresent, a threshold they argue fewer researchers would be willing to cross.[^1]

[^1]: Wiggins & Christopherson (2019)

::: {.notes}

- Préenregistrement optionnel!
- Clairement un problème de communication...
- Évite de la confusion!

:::

## « Big Teams Science » {.center}

![](images/psa.png){fig-align="center"}

::: {.notes}

Hundreds of labs that coordinates data collection for democratically selected studies.

Our mission is to accelerate the accumulation of reliable and generalizable evidence in psychological science, reducing the distance between truth about human behavior and mental processes and our current understanding. This challenge cannot be adequately met by a single researcher or small team. Instead, we attempt to meet this challenge with a distributed laboratory network that is ongoing (as opposed to time or task limited), diverse (both in terms of human subjects and participating researchers), and inclusive (we welcome ideas, contributions, study proposals, or other input from anyone in the field of psychology).

:::

---

![](images/psa_profile.png){fig-align="center"}

## L'importance de changements structurels

- Valoriser les bonnes pratiques et la science ouverte!
    - au-delà de e.g., nombre de publications, facteur d'impact, prestige des revues
    - par exemple lors du processus d'embauche des nouveaux profs
- Incorporer ces pratiques et ce discours formellement dans nos politiques universitaires
    - Merci Liesette!

---

![](images/nature.png){fig-align="center"}

## Des problèmes plus profonds... {.center}

## Confusion entre formation et production

- Techniquement, les chercheurs (profs) sont les producteurs de la science
- Les étudiants (doctorants) sont là pour apprendre comment produire de la bonne science
- Mais la dynamique actuelle a changé et encourage maintenant plus les étudiants à produire eux-mêmes la science—et rapidement
- C'est en effet ce qui détermine les chances d'acceptation
- Publiez ou périssez! (publish or perish)

::: {.notes}

- Le doctorat devient plutôt une occasion de prouver que nous sommes des bons producteurs de recherche, plutôt que d'apprendre
- Ceux et celles qui prennent le temps d'apprendre seront pénalisés à court-terme
- Le bénéfice seraient évidemment qu'à long-terme, ils produiraient de la meilleure recherche
- Mais cela ne fonctionne pas en pratique puisqu'ils sont exclus du monde académique en faveur des producteurs « hautement performants »
- E.g., pour être accepté au doc/post-doc/prof, pour avoir des bourses/subventions
- Nous avons donc créé un système favorisant les producteurs plutôt que les « appreneurs »

:::

## Pas de contrôle de qualité

> That Stapel managed to go so long undiscovered in his fraud again raised alarms about the possibility that the supposed quality control mechanisms in psychological science were somehow failing.[^1]

- Pas ou peu de contrôle de qualité, car cela ralentirait le processus de publication, de production!
- Qui supervise le superviseur?

[^1]: Wiggins & Christopherson (2019)

::: {.notes}
Pas normal qu'on fasse réviser le papier final par des collègues, et enfin par d'autres chercheurs lors du peer review, mais qu'on ne fasse pas réviser l'ensemble du reste du processus de la recherche, incluant la conceptualisation, le choix des mesures, l'implémentation des tâches et questionnaires dans les plateformes, etc., qui sont à la base de ces inférences.

:::

---

![](images/error.png){fig-align="center"}

## L'importance de la réflexion a priori {.center}

> If I had eight hours to chop down a tree, I’d spend six hours sharpening my axe

— Abraham Lincoln

::: {.notes}
Je pense qu'on peut apprendre de Abraham Lincoln, qui a dit : [...]

On ne passe pas assez de temps à aiguiser notre hache d'après moi. On connait l'adage : la qualité, pas la quantité! Malheureusement, c'est toujours la quantité qui prime. Même au-delà de la recherche, on nous surcharge de cours à prendre, plutôt que nous donner le temps de développer les méthodes, les outils, et l'expérience nécessaires pour faire de la recherche (ou de la clinique) correctement.

Dans mon expérience, peu de temps est accordé à la phase pré-recherche, puisqu'on est toujours pressé de « commencer l'étude » le plus rapidement possible, pour « faire avancer le projet ». Donc pas beaucoup de temps de réflexion nécessaire est passé sur la théorie et à la conception du devis de l'étude, mais également aux étapes découlant du devis, comme le type d'analyse statistique. Souvent, le type d'analyse statistique et son implémentation sont déterminés après que la collecte de données soit terminée, et qu'on soit rendu à l'étape d'analyse en tant que tel.

...

L'importance de la réflexivité (dans tous les aspects de la recherche)

:::


## Pas assez de temps (trop de lectures)

![](images/reading.png){fig-align="center"}

---

De longues sections méthodologiques et de résultats qui sont souvent peu pertinentes au point qui est en train d'être fait... Il existe un concept dans les compagnies où les individus sont payés à l'heure et quand il n'y a rien à faire, soit ils sont payés à rien faire, ou mieux, ils sont payé à faire des choses complètement inutiles et farfelues, juste pour dire qu'ils ne peuvent pas être sur leur téléphone, car ils sont payés, donc ils doivent travailler, même si c'est pas productif! Et donc je me demande si il n'y a pas un parallèle à faire ici, dans le sens qu'on se dit, mon dieu, ces gens là font un doctorat, faut faire quelque chose pour les garder occupés, sinon ça sera pas sérieux! Et notre solution? Plus de lectures!! Faut les garder occupés, même si ça la valeur ajoutée est faible! On focus sur les mauvaises affaires. Moins de temps sur les lectures, et plus de temps sur des projets intégrateurs appliqués! Les travaux, les présentations orales, les discussions, sont utiles dans ce sens là, donc ça fait du bien et ça fait changement du bac, mais d'après-moi on devrait aussi voir des exemples de cas appliqués en classe, et passer plus de temps à réfléchir dans par exemple des exercices interactifs plutôt que seulement sur des lectures théoriques. Système archaïque

---

::: {.r-fit-text}
- ...
- ...
- Trop d'information dilue le message
:::

## Formation plus appliquée

- ~ 700 articles scientifiques pour maitrise + doc combinés
  - ~ 2000 incluant bac (~ 6000 heures)
- Pas vraiment aidé à devenir un meilleur chercheur...
    - Dû aller chercher ces connaissances dans mon temps libre (normal??)
- Tradition ou bénéfice réel?
    - Bonne priorité? Quel est l'objectif?
    - "Train them or don't require them to produce!"

::: {.notes}
- Lecture de 6 heures...
- Exemple bac truc A+
- Lectures p
- Europe (doc)
- Mettre ce temps sur les bonnes pratiques et une formation pratique?
- Seul cours où on discute de ce sujet

:::

## Le problème de l'expertise éclatée {.center}



## Le problème des « preprints »

- Pas révisé par les pairs
- Pas de contrôle de qualité

- Donc besoin d'un système de preprints, mais avec peer-review

## Problèmes associées avec la révision par les pairs

- Outre les problèmes connus la révision par les pairs
- Problème que la révision par les pairs n'est pas valorisée
  - (mais voir Publons/Web of Science)
- Donc certains chercheurs ont comme politique de ne pas réviser les articles des autres, même si techniquement, ils le devraient...
- Mais comme les chercheurs sont débordés, selon certains professeurs, on accepte de réviser des articles que lorsque des « amis » ou « collaborateurs » nous le demande...
- Donc problème avec le système automatisé : ce n'est pas un ami ou une connaissance qui nous le demande! Donc est-ce que les gens seront susceptibles d'accepter??


## Système de révision par les pairs automatisé

- Avantage principal : Gain de temps (libération de ressources)
  - Requêtes auprès des réviseurs automatique
    - (mais supervisée par un éditeur humain)
  - Manuscrit formatté automatiquement par la plateforme
    - (mais peut être modifié par les auteurs eux-mêmes)
  - Pas de frais pour publier
  - Frais pour la plateforme assumée par un collectif formé de gouvernements et d'organismes scientifiques ou à but non-lucratif.

## Le problème du format « Journal »

- L'État finance la plupart des recherches
- L'État paie les salaires de la plupart de ceux qui vérifient la qualité de la recherche
- Puis, l'État achète la majeure partie du produit publié
- Système efficace?
- L'idée des journaux, du Facteur d'Impact, du prestige : malsain

---

![](images/profit.png){fig-align="center"}

## Des profits monstrueux

- Ils achètent la compétition pour développer un monopole
- 15% des publications en 1970 vs 53% aujourd'hui
- Marge de profit : 35% (> Apple, Google, Amazon)
- Elsevier : profits ~ 3.3 billions (Netflix ~ 7.7 billions)
- Couts estimés = 3.3 x 2.9 = 9.4 billions
- Mais aucune contribution scientifique...
- Une fraude déguisée?

::: {.notes}

https://conscienhealth.org/2017/06/publishing-science-impressive-profits-intellectual-property/
https://library.missouri.edu/news/lottes-health-sciences-library/one-journal-publishing-company-is-more-profitable-than-netflix

:::

---

![](images/mafia.png){fig-align="center"}

---

![](images/lobby.png){fig-align="center"}

## Un système de publication unifié 1/2

- Financé par le gouvernement ou des fondations
- Une seule place pour tous les articles
- Organisé par thème et sous-thèmes
- Avec plusieurs tags
- Genre de plateforme de preprints, mais peer-reviewed
- Plusieurs exemples de journaux accès libres sans frais de publications (e.g., JOSS)
- Pas de limites d'articles, effet tiroir réduit

## Un système de publication unifié 2/2

- On se débarasse du système de Facteur d'Impact
- Ou bien une notation alternative qui dépend de l'article, pas du journal
- Basé sur un mixe de :
    - évaluations des pairs
    - nombre de citations
    - « points » votés par les membres du système
    
## Analyse cout-bénéfices

- Éditeurs : toujours gratuit (ou pourrait avoir une certaine compensation)
- Réviseurs : toujours gratuit (ou pourrait avoir une certaine compensation)
- Couts pour développer/acheter la plateforme : ~500k
- Serveurs pour héberger la plateforme : 10k/année
- Autre frais administratifs : 10k/année
- Total = 500k au départ, puis 20k/année

Épargne de = 9999999999 millions

## Et s'il n'y avait plus d'électricité!????

- Plus gros problèmes (se nourrir, se transporter, se chauffer)
- Peut quand même imprimer sur du papier régulier
- Pour des besoins particuliers, ou pour des archives de l'humanité
- Couts d'impression très faibles, insignifiants

::: {.notes}

Lever la main ceux qui ont déjà lu un article scientifique papier à la bibliothèque plutôt que de faire imprimer un PDF depuis votre ordinateur

:::

## En résumé

- Mauvaises pratiques
- Problèmes d'intégrité
- Confusion entre formation et production
- Pas de contrôle de qualité
- Pas assez de temps pour « bien faire les choses »
- Un système de révision par les pairs inefficace
- Un système de publication des articles scandaleux
- Etc., etc.

---

## Quelques unes des causes de nos problèmes...{.center}

![](images/problems.png){fig-align="center"}

---

![](images/fine.jpg){fig-align="center"}

## Quelques unes des solutions possibles...{.center}

![](images/solutions.png){fig-align="center"}

## Apprentissage de R

Permet d'adresser :

- Transparence & réplicabilité
- Le problème de l'expertise éclatée (pédagogie, tutoriels)
- Formation et production combinées facilitée

N'adresse pas :

- La fraude
- La réflexion à priori (mais pré-enregistrement aide)

---

![](images/training_dotplot_se.png){fig-align="center"}

## Cours de sciences des données (avec R)

---

![](images/tradition.png){fig-align="center"}

![](images/practicum.png){fig-align="center"}

![](images/futurer.png){fig-align="center"}

![](images/in-house.png){fig-align="center"}

![](images/apa.png){fig-align="center"}

## Exemple de script R {.center}

https://remi-theriault.com/priming

## Conclusion

Parlez-en dans vos milieux!

Demander à vos collègues et directeurs de faire de la science ouverte!!

::: {.small}
(Créez vous un Twitter!)
:::

::: {.notes}
Donc en conclusion, que devriez-vous retenir de cette présentation!? Tout simplement, que la science psychologique fait face à de nombreux défis de taille, plusieurs structurels, mais que des solutions existent, et qu'avec un peu d'imagination, un peu de courage, et un peu d'amour et d'humour, on peut arriver à changer les choses et les pratiques autour de nous. Un premier pas, c'est d'en discuter entre nous et avec nos directeurs et directrices de recherche, nos collègues, et nos professeurs.

:::

## Questions de discussion

1. Dénoncer les mauvaises pratiques dans notre millieu?
2. La valorisation institutionnelle de la science ouverte?
3. Remplacer le cours de stats par un cours de sciences des données (avec R)?
4. La pertinence d'une base de données ouverte d'articles classés par thème plutôt que le format de type « journal »?
5. L'automatisation du processus de révision par les pairs
6. Tag confirmatoire vs. exploratoire pour les articles?
7. Authorship et financement pour toutes et tous?

::: {.notes}
Je sais que ça fait beaucoup... C'est pourquoi je vous ai préparé une liste de questions toute faites, vous n'avez qu'à choisir!

:::

## Remerciements

Diapos créées via R et Quarto.

## Iniquités en recherche {.center}

## Le critère d'authorship

Toute contribution significative devrait être reconnue de manière significative, i.e,. comme auteurs
